{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer\n",
    "\n",
    "import codecs\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "\n",
    "# import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__, tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jpn-english material\n",
    "path_to_file = \"./jpn-eng/jpn.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert model parameters\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 64\n",
    "OUTPUT_LAYER_NUM = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "PRETRAINED_PATH = 'bert-master/Japanese_L-12_H-768_A-12_E-30_BPE/'\n",
    "CONFIG_PATH = PRETRAINED_PATH + 'bert_config.json'\n",
    "CHECKPOINT_PATH = PRETRAINED_PATH + 'bert_model.ckpt'\n",
    "VOCAB_PATH = PRETRAINED_PATH + 'vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bert model\n",
    "bert_model = load_trained_model_from_checkpoint(\n",
    "  CONFIG_PATH,\n",
    "  CHECKPOINT_PATH,\n",
    "  training=False,\n",
    "  trainable=False,\n",
    "  output_layer_num=OUTPUT_LAYER_NUM,\n",
    "  seq_len=SEQ_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 14:12:56.373942 15000 deprecation_wrapper.py:119] From C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0829 14:12:56.398949 15000 deprecation_wrapper.py:119] From C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0829 14:12:56.499941 15000 deprecation_wrapper.py:119] From C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0829 14:12:56.501940 15000 deprecation_wrapper.py:119] From C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0829 14:12:56.514941 15000 deprecation.py:506] From C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0829 14:12:56.565944 15000 deprecation_wrapper.py:119] From C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare token->idx dictionary\n",
    "def make_token_dict(vocab_path):\n",
    "  token_dict = {}\n",
    "  with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "      if line != ' \\n':\n",
    "        token = line.strip()\n",
    "      else:\n",
    "        token = line.strip('\\n')\n",
    "      token_dict[token] = len(token_dict)\n",
    "  return token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eng_sentence(w):\n",
    "    w = w.lower().strip()\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '[CLS] ' + w + ' [SEP]'\n",
    "    return w\n",
    "\n",
    "def preprocess_jpn_sentence(w):\n",
    "    m = MeCab.Tagger (\"-Owakati\")\n",
    "    w = '[CLS] ' + m.parse(w).strip().strip('\\n') + ' [SEP]'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    eng, jpn = [], []\n",
    "    for l in lines[:num_examples]:\n",
    "#         (eng_sentence, jpn_sentence) = l.split('\\t')\n",
    "        (eng_sentence, _) = l.split('\\t')\n",
    "        eng.append(preprocess_eng_sentence(eng_sentence))\n",
    "#         jpn.append(preprocess_jpn_sentence(jpn_sentence))\n",
    "    return eng, jpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng, jpn = create_dataset(path_to_file, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eng[3])\n",
    "print(jpn[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    # convert words(of a sentence) into word indexes\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "                     filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    # padding word indexes(of sentences) to the same length(using maximum length of all sentences)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                           padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "# def load_dataset(path, num_examples=None):\n",
    "#     # creating cleaned input, output pairs\n",
    "#     targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "#     input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "#     target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "#     return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, input_vocab_path, num_examples=None, verbose=False):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, _ = create_dataset(path, num_examples)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  input_token_dict = make_token_dict(input_vocab_path)\n",
    "  inp_lang_tokenizer = Tokenizer(input_token_dict, cased=True)\n",
    "  \n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  inp_ids, inp_segments = [], []\n",
    "  for l in lines[:num_examples]:\n",
    "      (_, jpn_sentence) = l.split('\\t')\n",
    "      id, segment = inp_lang_tokenizer.encode(jpn_sentence, max_len=SEQ_LEN)\n",
    "      inp_ids.append(id)\n",
    "      inp_segments.append(segment)\n",
    "      if verbose:\n",
    "        print('{}->{}{}'.format(jpn_sentence, id, segment))\n",
    "  \n",
    "\n",
    "  return inp_ids, inp_segments, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ids, inp_segments, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, VOCAB_PATH, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000 36000 9000 9000\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 45000\n",
    "# input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "inp_ids, inp_segments, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, VOCAB_PATH, num_examples)\n",
    "input_tensor = []\n",
    "for i, s in zip(inp_ids, inp_segments):\n",
    "  input_tensor.append([i,s])\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "# max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), SEQ_LEN\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['の']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_lang.decode([2, 5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 64\n"
     ]
    }
   ],
   "source": [
    "print(max_length_targ, max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  if isinstance(lang, tf.keras.preprocessing.text.Tokenizer):\n",
    "    for t in tensor:\n",
    "      if t!=0:\n",
    "        print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "  else:\n",
    "    print (lang.decode(tensor))\n",
    "\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0][0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000\n"
     ]
    }
   ],
   "source": [
    "print(len(input_tensor_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "# BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 3072 # concatenation of last 4 layer ouputs of Transformer\n",
    "units = 1024\n",
    "# vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_inp_size = len(inp_lang._token_dict)\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32005 8844\n",
      "(64, 64)\n",
      "36000\n"
     ]
    }
   ],
   "source": [
    "print(vocab_inp_size, vocab_tar_size)\n",
    "input_tensor_train = np.array(input_tensor_train)\n",
    "print(input_tensor_train[:64, 1, :].shape)\n",
    "print(len(input_tensor_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz, bert_model=None):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        if not bert_model:\n",
    "          self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "          self.embedding = bert_model\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden, bert_model=False):\n",
    "        if not bert_model:\n",
    "          x = self.embedding(x)\n",
    "        else:\n",
    "          x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[    2,   149,  1099,     9, 23025,  4330,  1607,  1512,     5,\n",
      "         3191,    10,   940, 10759,   668,     7,     3,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [    2,  8882,   226,     8,  9013,  1357,   429,  4330,   635,\n",
      "         1247, 16614,   856,     7,     3,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
      "(2, 64)\n"
     ]
    }
   ],
   "source": [
    "example_input_batch = input_tensor_train[:2]\n",
    "print([example_input_batch[:, 0, :], example_input_batch[:, 1, :]])\n",
    "print(example_input_batch[:, 0, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in converted code:\n\n    <ipython-input-105-99ea45c21904>:20 call *\n        output, state = self.gru(x, initial_state = hidden)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:669 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:663 __call__\n        inputs, outputs, args, kwargs)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1708 _set_connectivity_metadata_\n        input_tensors=inputs, output_tensors=outputs, arguments=kwargs)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1795 _add_inbound_node\n        input_tensors)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:515 map_structure\n        structure[0], [func(*x) for x in entries],\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:515 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1794 <lambda>\n        inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\n    AttributeError: 'tuple' object has no attribute 'layer'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-c435f040adeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mexample_input_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msample_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mexample_input_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_input_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Encoder output shape: (batch size, sequence length, units) {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Encoder Hidden state shape: (batch size, units) {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_hidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in converted code:\n\n    <ipython-input-105-99ea45c21904>:20 call *\n        output, state = self.gru(x, initial_state = hidden)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:669 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:663 __call__\n        inputs, outputs, args, kwargs)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1708 _set_connectivity_metadata_\n        input_tensors=inputs, output_tensors=outputs, arguments=kwargs)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1795 _add_inbound_node\n        input_tensors)\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:515 map_structure\n        structure[0], [func(*x) for x in entries],\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:515 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    C:\\Users\\di.sun\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1794 <lambda>\n        inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\n    AttributeError: 'tuple' object has no attribute 'layer'\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE, bert_model=bert_model)\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "example_input_batch = input_tensor_train[:64]\n",
    "\n",
    "sample_output, sample_hidden = encoder([example_input_batch[:, 0, :], example_input_batch[:, 1, :]], sample_hidden, bert_model=True)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 44, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 8844)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt-45k-30epoch\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.7420\n",
      "Epoch 1 Batch 100 Loss 1.4641\n",
      "Epoch 1 Batch 200 Loss 1.5757\n",
      "Epoch 1 Batch 300 Loss 1.3221\n",
      "Epoch 1 Batch 400 Loss 1.3000\n",
      "Epoch 1 Batch 500 Loss 1.2700\n",
      "Epoch 1 Loss 1.4130\n",
      "Time taken for 1 epoch 2605.316736459732 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.2374\n",
      "Epoch 2 Batch 100 Loss 1.1347\n",
      "Epoch 2 Batch 200 Loss 1.3038\n",
      "Epoch 2 Batch 300 Loss 1.0643\n",
      "Epoch 2 Batch 400 Loss 1.0721\n",
      "Epoch 2 Batch 500 Loss 1.0474\n",
      "Epoch 2 Loss 1.0984\n",
      "Time taken for 1 epoch 2553.679552793503 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0400\n",
      "Epoch 3 Batch 100 Loss 0.9062\n",
      "Epoch 3 Batch 200 Loss 1.1028\n",
      "Epoch 3 Batch 300 Loss 0.8526\n",
      "Epoch 3 Batch 400 Loss 0.8548\n",
      "Epoch 3 Batch 500 Loss 0.8447\n",
      "Epoch 3 Loss 0.8941\n",
      "Time taken for 1 epoch 2550.599761724472 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8187\n",
      "Epoch 4 Batch 100 Loss 0.6904\n",
      "Epoch 4 Batch 200 Loss 0.8948\n",
      "Epoch 4 Batch 300 Loss 0.6628\n",
      "Epoch 4 Batch 400 Loss 0.6428\n",
      "Epoch 4 Batch 500 Loss 0.6388\n",
      "Epoch 4 Loss 0.6873\n",
      "Time taken for 1 epoch 2556.8588938713074 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.5981\n",
      "Epoch 5 Batch 100 Loss 0.4820\n",
      "Epoch 5 Batch 200 Loss 0.7078\n",
      "Epoch 5 Batch 300 Loss 0.4902\n",
      "Epoch 5 Batch 400 Loss 0.4745\n",
      "Epoch 5 Batch 500 Loss 0.4541\n",
      "Epoch 5 Loss 0.5087\n",
      "Time taken for 1 epoch 2554.768421649933 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4418\n",
      "Epoch 6 Batch 100 Loss 0.3452\n",
      "Epoch 6 Batch 200 Loss 0.5482\n",
      "Epoch 6 Batch 300 Loss 0.3679\n",
      "Epoch 6 Batch 400 Loss 0.3653\n",
      "Epoch 6 Batch 500 Loss 0.3423\n",
      "Epoch 6 Loss 0.3719\n",
      "Time taken for 1 epoch 2559.096219062805 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3286\n",
      "Epoch 7 Batch 100 Loss 0.2376\n",
      "Epoch 7 Batch 200 Loss 0.4208\n",
      "Epoch 7 Batch 300 Loss 0.2802\n",
      "Epoch 7 Batch 400 Loss 0.2789\n",
      "Epoch 7 Batch 500 Loss 0.2484\n",
      "Epoch 7 Loss 0.2762\n",
      "Time taken for 1 epoch 2554.053637981415 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2530\n",
      "Epoch 8 Batch 100 Loss 0.1927\n",
      "Epoch 8 Batch 200 Loss 0.3308\n",
      "Epoch 8 Batch 300 Loss 0.2145\n",
      "Epoch 8 Batch 400 Loss 0.1998\n",
      "Epoch 8 Batch 500 Loss 0.1871\n",
      "Epoch 8 Loss 0.2078\n",
      "Time taken for 1 epoch 2555.9981713294983 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1960\n",
      "Epoch 9 Batch 100 Loss 0.1432\n",
      "Epoch 9 Batch 200 Loss 0.2413\n",
      "Epoch 9 Batch 300 Loss 0.1584\n",
      "Epoch 9 Batch 400 Loss 0.1603\n",
      "Epoch 9 Batch 500 Loss 0.1435\n",
      "Epoch 9 Loss 0.1591\n",
      "Time taken for 1 epoch 2557.1234340667725 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1697\n",
      "Epoch 10 Batch 100 Loss 0.1056\n",
      "Epoch 10 Batch 200 Loss 0.1985\n",
      "Epoch 10 Batch 300 Loss 0.1208\n",
      "Epoch 10 Batch 400 Loss 0.1047\n",
      "Epoch 10 Batch 500 Loss 0.1101\n",
      "Epoch 10 Loss 0.1222\n",
      "Time taken for 1 epoch 2558.7704317569733 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1104\n",
      "Epoch 11 Batch 100 Loss 0.0815\n",
      "Epoch 11 Batch 200 Loss 0.1327\n",
      "Epoch 11 Batch 300 Loss 0.1226\n",
      "Epoch 11 Batch 400 Loss 0.0831\n",
      "Epoch 11 Batch 500 Loss 0.0871\n",
      "Epoch 11 Loss 0.0951\n",
      "Time taken for 1 epoch 2556.924262523651 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0882\n",
      "Epoch 12 Batch 100 Loss 0.0681\n",
      "Epoch 12 Batch 200 Loss 0.1218\n",
      "Epoch 12 Batch 300 Loss 0.0962\n",
      "Epoch 12 Batch 400 Loss 0.0666\n",
      "Epoch 12 Batch 500 Loss 0.0701\n",
      "Epoch 12 Loss 0.0760\n",
      "Time taken for 1 epoch 2559.4303510189056 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0687\n",
      "Epoch 13 Batch 100 Loss 0.0477\n",
      "Epoch 13 Batch 200 Loss 0.0916\n",
      "Epoch 13 Batch 300 Loss 0.0869\n",
      "Epoch 13 Batch 400 Loss 0.0515\n",
      "Epoch 13 Batch 500 Loss 0.0666\n",
      "Epoch 13 Loss 0.0622\n",
      "Time taken for 1 epoch 2559.471154689789 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0671\n",
      "Epoch 14 Batch 100 Loss 0.0516\n",
      "Epoch 14 Batch 200 Loss 0.0663\n",
      "Epoch 14 Batch 300 Loss 0.0575\n",
      "Epoch 14 Batch 400 Loss 0.0464\n",
      "Epoch 14 Batch 500 Loss 0.0611\n",
      "Epoch 14 Loss 0.0521\n",
      "Time taken for 1 epoch 2566.9926290512085 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0542\n",
      "Epoch 15 Batch 100 Loss 0.0415\n",
      "Epoch 15 Batch 200 Loss 0.0537\n",
      "Epoch 15 Batch 300 Loss 0.0641\n",
      "Epoch 15 Batch 400 Loss 0.0455\n",
      "Epoch 15 Batch 500 Loss 0.0625\n",
      "Epoch 15 Loss 0.0482\n",
      "Time taken for 1 epoch 2563.6380310058594 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0458\n",
      "Epoch 16 Batch 100 Loss 0.0457\n",
      "Epoch 16 Batch 200 Loss 0.0635\n",
      "Epoch 16 Batch 300 Loss 0.0538\n",
      "Epoch 16 Batch 400 Loss 0.0388\n",
      "Epoch 16 Batch 500 Loss 0.0643\n",
      "Epoch 16 Loss 0.0449\n",
      "Time taken for 1 epoch 2564.1997380256653 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0537\n",
      "Epoch 17 Batch 100 Loss 0.0484\n",
      "Epoch 17 Batch 200 Loss 0.0517\n",
      "Epoch 17 Batch 300 Loss 0.0447\n",
      "Epoch 17 Batch 400 Loss 0.0378\n",
      "Epoch 17 Batch 500 Loss 0.0541\n",
      "Epoch 17 Loss 0.0416\n",
      "Time taken for 1 epoch 2563.1044068336487 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0507\n",
      "Epoch 18 Batch 100 Loss 0.0367\n",
      "Epoch 18 Batch 200 Loss 0.0847\n",
      "Epoch 18 Batch 300 Loss 0.0656\n",
      "Epoch 18 Batch 400 Loss 0.0469\n",
      "Epoch 18 Batch 500 Loss 0.0384\n",
      "Epoch 18 Loss 0.0447\n",
      "Time taken for 1 epoch 2643.1630249023438 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0374\n",
      "Epoch 19 Batch 100 Loss 0.0390\n",
      "Epoch 19 Batch 200 Loss 0.0640\n",
      "Epoch 19 Batch 300 Loss 0.0542\n",
      "Epoch 19 Batch 400 Loss 0.0289\n",
      "Epoch 19 Batch 500 Loss 0.0278\n",
      "Epoch 19 Loss 0.0380\n",
      "Time taken for 1 epoch 2561.0377748012543 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0354\n",
      "Epoch 20 Batch 100 Loss 0.0363\n",
      "Epoch 20 Batch 200 Loss 0.0486\n",
      "Epoch 20 Batch 300 Loss 0.0591\n",
      "Epoch 20 Batch 400 Loss 0.0314\n",
      "Epoch 20 Batch 500 Loss 0.0296\n",
      "Epoch 20 Loss 0.0328\n",
      "Time taken for 1 epoch 2550.2844111919403 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0407\n",
      "Epoch 21 Batch 100 Loss 0.0356\n",
      "Epoch 21 Batch 200 Loss 0.0437\n",
      "Epoch 21 Batch 300 Loss 0.0378\n",
      "Epoch 21 Batch 400 Loss 0.0292\n",
      "Epoch 21 Batch 500 Loss 0.0340\n",
      "Epoch 21 Loss 0.0299\n",
      "Time taken for 1 epoch 2569.689178943634 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0279\n",
      "Epoch 22 Batch 100 Loss 0.0398\n",
      "Epoch 22 Batch 200 Loss 0.0374\n",
      "Epoch 22 Batch 300 Loss 0.0408\n",
      "Epoch 22 Batch 400 Loss 0.0323\n",
      "Epoch 22 Batch 500 Loss 0.0274\n",
      "Epoch 22 Loss 0.0294\n",
      "Time taken for 1 epoch 2550.5540001392365 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0257\n",
      "Epoch 23 Batch 100 Loss 0.0286\n",
      "Epoch 23 Batch 200 Loss 0.0455\n",
      "Epoch 23 Batch 300 Loss 0.0447\n",
      "Epoch 23 Batch 400 Loss 0.0280\n",
      "Epoch 23 Batch 500 Loss 0.0408\n",
      "Epoch 23 Loss 0.0311\n",
      "Time taken for 1 epoch 2547.938145637512 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0379\n",
      "Epoch 24 Batch 100 Loss 0.0333\n",
      "Epoch 24 Batch 200 Loss 0.0369\n",
      "Epoch 24 Batch 300 Loss 0.0367\n",
      "Epoch 24 Batch 400 Loss 0.0363\n",
      "Epoch 24 Batch 500 Loss 0.0406\n",
      "Epoch 24 Loss 0.0311\n",
      "Time taken for 1 epoch 2550.1060585975647 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0227\n",
      "Epoch 25 Batch 100 Loss 0.0310\n",
      "Epoch 25 Batch 200 Loss 0.0390\n",
      "Epoch 25 Batch 300 Loss 0.0378\n",
      "Epoch 25 Batch 400 Loss 0.0299\n",
      "Epoch 25 Batch 500 Loss 0.0327\n",
      "Epoch 25 Loss 0.0311\n",
      "Time taken for 1 epoch 2547.8530411720276 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0265\n",
      "Epoch 26 Batch 100 Loss 0.0275\n",
      "Epoch 26 Batch 200 Loss 0.0404\n",
      "Epoch 26 Batch 300 Loss 0.0457\n",
      "Epoch 26 Batch 400 Loss 0.0316\n",
      "Epoch 26 Batch 500 Loss 0.0400\n",
      "Epoch 26 Loss 0.0310\n",
      "Time taken for 1 epoch 2564.14524769783 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0375\n",
      "Epoch 27 Batch 100 Loss 0.0248\n",
      "Epoch 27 Batch 200 Loss 0.0450\n",
      "Epoch 27 Batch 300 Loss 0.0553\n",
      "Epoch 27 Batch 400 Loss 0.0303\n",
      "Epoch 27 Batch 500 Loss 0.0247\n",
      "Epoch 27 Loss 0.0278\n",
      "Time taken for 1 epoch 2563.050482273102 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0317\n",
      "Epoch 28 Batch 100 Loss 0.0339\n",
      "Epoch 28 Batch 200 Loss 0.0317\n",
      "Epoch 28 Batch 300 Loss 0.0324\n",
      "Epoch 28 Batch 400 Loss 0.0304\n",
      "Epoch 28 Batch 500 Loss 0.0246\n",
      "Epoch 28 Loss 0.0280\n",
      "Time taken for 1 epoch 2565.4317762851715 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0366\n",
      "Epoch 29 Batch 100 Loss 0.0347\n",
      "Epoch 29 Batch 200 Loss 0.0368\n",
      "Epoch 29 Batch 300 Loss 0.0403\n",
      "Epoch 29 Batch 400 Loss 0.0219\n",
      "Epoch 29 Batch 500 Loss 0.0360\n",
      "Epoch 29 Loss 0.0289\n",
      "Time taken for 1 epoch 2564.656318664551 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0273\n",
      "Epoch 30 Batch 100 Loss 0.0289\n",
      "Epoch 30 Batch 200 Loss 0.0418\n",
      "Epoch 30 Batch 300 Loss 0.0439\n",
      "Epoch 30 Batch 400 Loss 0.0213\n",
      "Epoch 30 Batch 500 Loss 0.0384\n",
      "Epoch 30 Loss 0.0295\n",
      "Time taken for 1 epoch 2571.4970347881317 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, verbose=False):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    if verbose == True:\n",
    "        print('Original sentence: {}'.format(sentence))\n",
    "\n",
    "    sentence = preprocess_jpn_sentence(sentence)\n",
    "    if verbose == True:\n",
    "        print('Preprocessed sentence: {}'.format(sentence))\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    if verbose == True:\n",
    "        print('Word sequences of sentence: {}'.format(inputs))\n",
    "        \n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    if verbose == True:\n",
    "        print('Paded sequences of sentence: {}'.format(inputs))\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    if verbose == True:\n",
    "        print('Tensor of sentence: {}'.format(inputs))\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    if verbose == True:\n",
    "        print('enc_out: {}'.format(enc_out))\n",
    "        print('enc_hidden: {}'.format(enc_hidden))\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    if verbose == True:\n",
    "        print('dec_input: {}'.format(dec_input))\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        if verbose == True:\n",
    "            print('dec_input: {}'.format(dec_input))\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, verbose=False):\n",
    "    result, sentence, attention_plot = evaluate(sentence, verbose)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2af9a36a0f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> 雨 が 嫌い 。 <end>\n",
      "Predicted translation: i don t like rain . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 38632 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 12364 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 23244 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 12356 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 12290 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:176: RuntimeWarning: Glyph 38632 missing from current font.\n",
      "  font.load_char(ord(s), flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:176: RuntimeWarning: Glyph 12364 missing from current font.\n",
      "  font.load_char(ord(s), flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 23244 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 12356 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\Alice\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:176: RuntimeWarning: Glyph 12290 missing from current font.\n",
      "  font.load_char(ord(s), flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'雨が嫌い。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: いい天気ですね。\n",
      "Preprocessed sentence: <start> いい 天気 です ね 。 <end>\n",
      "Word sequences of sentence: [1, 45, 415, 20, 59, 3, 2]\n",
      "Paded sequences of sentence: [[  1  45 415  20  59   3   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]]\n",
      "Tensor of sentence: [[  1  45 415  20  59   3   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]]\n",
      "enc_out: [[[ 0.00549655 -0.10430124  0.00152233 ...  0.02123659 -0.03486874\n",
      "   -0.10197296]\n",
      "  [ 0.00390758 -0.16195562  0.00699065 ...  0.3110405  -0.04618217\n",
      "   -0.1307275 ]\n",
      "  [ 0.03408554 -0.5232086  -0.5766188  ...  0.37764972 -0.9423333\n",
      "   -0.12432431]\n",
      "  ...\n",
      "  [ 0.07000643  0.4793058   0.06101694 ... -0.9345466  -0.92021734\n",
      "   -0.09653044]\n",
      "  [ 0.07000935  0.47959706  0.06101688 ... -0.93420655 -0.92021734\n",
      "   -0.09653616]\n",
      "  [ 0.07001245  0.47989005  0.06101682 ... -0.93386483 -0.92021734\n",
      "   -0.09654184]]]\n",
      "enc_hidden: [[ 0.07001245  0.47989005  0.06101682 ... -0.93386483 -0.92021734\n",
      "  -0.09654184]]\n",
      "dec_input: [[1]]\n",
      "dec_input: [[16]]\n",
      "dec_input: [[18]]\n",
      "dec_input: [[7]]\n",
      "dec_input: [[340]]\n",
      "dec_input: [[88]]\n",
      "dec_input: [[3]]\n",
      "Input: <start> いい 天気 です ね 。 <end>\n",
      "Predicted translation: it s a nice day . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('いい天気ですね。', verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
