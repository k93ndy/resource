{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import MeCab\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file\n",
    "path_to_file = \"./jpn-eng/jpn.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eng_sentence(w):\n",
    "    w = w.lower().strip()\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "def preprocess_jpn_sentence(w):\n",
    "    m = MeCab.Tagger (\"-Owakati\")\n",
    "    w = '<start> ' + m.parse(w).strip().strip('\\n') + ' <end>'\n",
    "    return w\n",
    "\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    eng, jpn = [], []\n",
    "    for l in lines[:num_examples]:\n",
    "        (eng_sentence, jpn_sentence) = l.split('\\t')\n",
    "        eng.append(preprocess_eng_sentence(eng_sentence))\n",
    "        jpn.append(preprocess_jpn_sentence(jpn_sentence))\n",
    "    return eng, jpn\n",
    "  \n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    # convert words(of a sentence) into word indexes\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "                     filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    # padding word indexes(of sentences) to the same length(using maximum length of all sentences)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                           padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000 36000 9000 9000\n",
      "29 44\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 45000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "print(max_length_targ, max_length_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "99 ----> 今日\n",
      "4 ----> は\n",
      "2433 ----> ついて\n",
      "16 ----> ない\n",
      "3 ----> 。\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "25 ----> this\n",
      "129 ----> isn\n",
      "13 ----> t\n",
      "22 ----> my\n",
      "88 ----> day\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "# vocab_inp_size = len(inp_lang.word_index)+1\n",
    "# vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=26, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask, verbose=False):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  if verbose:\n",
    "    print('matmul_qk: {}'.format(matmul_qk))\n",
    "    \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "  if verbose:\n",
    "    print('scaled_attention_logits: {}'.format(scaled_attention_logits))\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v, verbose=False):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None, verbose)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_qk: [[  0. 100.   0.   0.]]\n",
      "scaled_attention_logits: [[ 0.       57.735027  0.        0.      ]]\n",
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_qk: [[  0.   0. 100. 100.]]\n",
      "scaled_attention_logits: [[ 0.        0.       57.735027 57.735027]]\n",
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_qk: [[100. 100.   0.   0.]]\n",
      "scaled_attention_logits: [[57.735027 57.735027  0.        0.      ]]\n",
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_qk: [[  0.   0. 100. 100.]\n",
      " [  0. 100.   0.   0.]\n",
      " [100. 100.   0.   0.]]\n",
      "scaled_attention_logits: [[ 0.        0.       57.735027 57.735027]\n",
      " [ 0.       57.735027  0.        0.      ]\n",
      " [57.735027 57.735027  0.        0.      ]]\n",
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# pass all the queries together\n",
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500)\n",
    "\n",
    "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
    "                                       training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
    "               rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(target_vocab_size, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000)\n",
    "\n",
    "output, attn = sample_decoder(tf.random.uniform((64, 26)), \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False, look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 26, 8000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 62))\n",
    "temp_target = tf.random.uniform((64, 26))\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13827 8845\n"
     ]
    }
   ],
   "source": [
    "num_layers = 6 # 6 in the paper\n",
    "d_model = 512 # 512 in the paper\n",
    "dff = 2048 # 2048 in the paper\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang.word_index) + 3\n",
    "target_vocab_size = len(targ_lang.word_index) + 2\n",
    "dropout_rate = 0.1\n",
    "\n",
    "print(input_vocab_size, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./transformer_checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64), # care default length of integer\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "# @tf.function(input_signature=train_step_signature)\n",
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence, verbose=False):\n",
    "  inp_sentence = preprocess_jpn_sentence(inp_sentence)\n",
    "  \n",
    "  inputs = [inp_lang.word_index[i] for i in inp_sentence.split(' ')]\n",
    "  \n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "  \n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "#   encoder_input = tf.expand_dims(inputs, 0)\n",
    "  encoder_input = inputs\n",
    "  if verbose:\n",
    "    print('encoder_input: {} {}'.format(encoder_input, encoder_input.shape))\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [targ_lang.word_index['<start>']]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "  if verbose:\n",
    "    print('initial output: {} {}'.format(output, output.shape))\n",
    "    \n",
    "  for i in range(max_length_targ):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "    if verbose:\n",
    "      print(enc_padding_mask, '\\n', combined_mask, '\\n', dec_padding_mask)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if targ_lang.index_word[int(predicted_id)] == '<end>':\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(48, 24))\n",
    "  \n",
    "  sentence = preprocess_jpn_sentence(sentence)\n",
    "  sentence = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "#   sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(8, 1, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :len(sentence)], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 16}\n",
    "\n",
    "    ax.set_xticks(range(len(sentence)))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        [inp_lang.index_word[i] for i in sentence], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([targ_lang.index_word[i] for i in result], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot='', verbose=False):\n",
    "  result, attention_weights = evaluate(sentence, verbose=verbose)\n",
    "  \n",
    "  result = result.numpy()\n",
    "  predicted_sentence = ''\n",
    "  for x in result:\n",
    "    predicted_sentence += targ_lang.index_word[x]\n",
    "    predicted_sentence += ' '\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 外は雪ですね。\n",
      "Predicted translation: <start> it s snowing outside . \n"
     ]
    }
   ],
   "source": [
    "test = '外は雪ですね。'\n",
    "# translate(test, plot='decoder_layer6_block2', verbose=False)\n",
    "translate(test, plot='', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 助けが必要です。\n",
      "Predicted translation: <start> i need your help . \n"
     ]
    }
   ],
   "source": [
    "translate('助けが必要です。', plot='', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: いい天気ですね。\n",
      "Predicted translation: <start> it s really hot today . \n"
     ]
    }
   ],
   "source": [
    "translate('いい天気ですね。', plot='', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate('どうすればいいでしょうか？', plot='decoder_layer6_block2', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 釣りにいきませんか？\n",
      "Predicted translation: <start> would you rather go on ? \n"
     ]
    }
   ],
   "source": [
    "translate('釣りにいきませんか？', plot='', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 学生時代のテストはいつも一夜漬けでした。\n",
      "Predicted translation: <start> when i was in college , i always studied most of the night just before a test . \n"
     ]
    }
   ],
   "source": [
    "translate('学生時代のテストはいつも一夜漬けでした。', plot='', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(input_tensor_val.shape[0]).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def validate_step(inp, tar):\n",
    "  encoder_input = inp\n",
    "#   print('batch inp:{}'.format(inp.shape))\n",
    "  decoder_input = [targ_lang.word_index['<start>']]*BATCH_SIZE\n",
    "  output = tf.expand_dims(decoder_input, 1)\n",
    "#   print('batch output_shape:{}'.format(output.shape))\n",
    "  \n",
    "  predictions_full = tf.zeros([BATCH_SIZE, 1, target_vocab_size])\n",
    "  for i in range(max_length_targ-1):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, _ = transformer(encoder_input, \n",
    "                                 output,\n",
    "                                 False,\n",
    "                                 enc_padding_mask,\n",
    "                                 combined_mask,\n",
    "                                 dec_padding_mask)\n",
    "    \n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "    predictions_full = tf.concat([predictions_full, predictions], axis=1)\n",
    "    print(predictions_full.shape)\n",
    "#     print('predictions:{}'.format(predictions.shape))\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "#     print('predicted_id:{}'.format(predicted_id.shape))\n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "#     print('output after one loop:{}'.format(output.shape))\n",
    "\n",
    "  predictions = predictions_full[:, 1:, :]\n",
    "  print('predictions:{}'.format(predictions))\n",
    "  loss = loss_function(tar[:, 1:], predictions)\n",
    "  \n",
    "  val_loss(loss)\n",
    "  val_accuracy(tar[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2, 8845)\n",
      "(64, 3, 8845)\n",
      "(64, 4, 8845)\n",
      "(64, 5, 8845)\n",
      "(64, 6, 8845)\n",
      "(64, 7, 8845)\n",
      "(64, 8, 8845)\n",
      "(64, 9, 8845)\n",
      "(64, 10, 8845)\n",
      "(64, 11, 8845)\n",
      "(64, 12, 8845)\n",
      "(64, 13, 8845)\n",
      "(64, 14, 8845)\n",
      "(64, 15, 8845)\n",
      "(64, 16, 8845)\n",
      "(64, 17, 8845)\n",
      "(64, 18, 8845)\n",
      "(64, 19, 8845)\n",
      "(64, 20, 8845)\n",
      "(64, 21, 8845)\n",
      "(64, 22, 8845)\n",
      "(64, 23, 8845)\n",
      "(64, 24, 8845)\n",
      "(64, 25, 8845)\n",
      "(64, 26, 8845)\n",
      "(64, 27, 8845)\n",
      "(64, 28, 8845)\n",
      "(64, 29, 8845)\n",
      "predictions:Tensor(\"strided_slice_140:0\", shape=(64, 28, 8845), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "val_loss.reset_states()\n",
    "val_accuracy.reset_states()\n",
    "\n",
    "# inp -> portuguese, tar -> english\n",
    "for (batch, (inp, tar)) in enumerate(val_dataset):\n",
    "  validate_step(inp, tar)\n",
    "\n",
    "print ('Validation Loss {:.4f} Accuracy {:.4f}'.format(train_loss.result(), train_accuracy.result()))\n",
    "print ('Time taken for validation: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8845"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
